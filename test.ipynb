{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5285a3a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0991ff83",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('ces_hourly_earnings_2022_2025.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "eb519689",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('2022-01-01', '2025-12-01')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(\"industry\")[\"avg_hourly_earnings\"].describe()\n",
        "df[\"date\"].min(), df[\"date\"].max()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "77b14eb5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.6)\n",
            "Requirement already satisfied: sentence-transformers in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.1)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
            "     ------------------------------------- 493.7/493.7 KB 10.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.3.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl (8.9 MB)\n",
            "     ---------------------------------------- 8.9/8.9 MB 11.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2023.3)\n",
            "Collecting transformers<6.0.0,>=4.41.0\n",
            "  Downloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
            "     --------------------------------------- 12.0/12.0 MB 11.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\ammsh\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (0.35.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: requests in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.9.2)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.12.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2023.8.8)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0\n",
            "  Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
            "     ---------------------------------------- 2.7/2.7 MB 10.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2023.7.22)\n",
            "Installing collected packages: scikit-learn, tokenizers, transformers, sentence-transformers\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.3.2\n",
            "    Uninstalling scikit-learn-1.3.2:\n",
            "      Successfully uninstalled scikit-learn-1.3.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.3\n",
            "    Uninstalling tokenizers-0.13.3:\n",
            "      Successfully uninstalled tokenizers-0.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.33.3\n",
            "    Uninstalling transformers-4.33.3:\n",
            "      Successfully uninstalled transformers-4.33.3\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 2.6.1\n",
            "    Uninstalling sentence-transformers-2.6.1:\n",
            "      Successfully uninstalled sentence-transformers-2.6.1\n",
            "Successfully installed scikit-learn-1.7.2 sentence-transformers-5.2.0 tokenizers-0.22.2 transformers-4.57.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 22.0.4; however, version 25.3 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install -U pandas numpy sentence-transformers scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "59de71c5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy<2\n",
            "  Downloading numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
            "     --------------------------------------- 15.8/15.8 MB 11.3 MB/s eta 0:00:00\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\ammsh\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\~umpy.libs\\\\libscipy_openblas64_-13e2df515630b4a41f92893938845698.dll'\n",
            "Consider using the `--user` option or check the permissions.\n",
            "\n",
            "WARNING: You are using pip version 22.0.4; however, version 25.3 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers==2.2.2\n",
            "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
            "Collecting transformers==4.35.0\n",
            "  Using cached transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers==2.2.2) (1.7.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers==2.2.2) (1.15.3)\n",
            "Requirement already satisfied: nltk in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers==2.2.2) (1.26.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers==2.2.2) (0.35.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers==2.2.2) (2.8.0)\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers==2.2.2) (0.2.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers==2.2.2) (4.67.1)\n",
            "Requirement already satisfied: torchvision in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers==2.2.2) (0.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.35.0) (2023.8.8)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.35.0) (0.6.2)\n",
            "Requirement already satisfied: requests in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.35.0) (2.32.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.35.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.35.0) (6.0.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers==4.35.0) (3.12.4)\n",
            "Collecting tokenizers<0.15,>=0.14\n",
            "  Downloading tokenizers-0.14.1-cp310-none-win_amd64.whl (2.2 MB)\n",
            "     ---------------------------------------- 2.2/2.2 MB 10.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.9.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ammsh\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.15.0)\n",
            "Collecting huggingface-hub>=0.4.0\n",
            "  Using cached huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "Requirement already satisfied: networkx in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.4.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: colorama in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->sentence-transformers==2.2.2) (0.4.6)\n",
            "Requirement already satisfied: click in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (8.1.3)\n",
            "Requirement already satisfied: joblib in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (1.5.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers==4.35.0) (2023.7.22)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers==4.35.0) (3.2.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers==4.35.0) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers==4.35.0) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision->sentence-transformers==2.2.2) (8.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ammsh\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (3.0.2)\n",
            "Installing collected packages: huggingface-hub, tokenizers, transformers, sentence-transformers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.35.1\n",
            "    Uninstalling huggingface-hub-0.35.1:\n",
            "      Successfully uninstalled huggingface-hub-0.35.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.4\n",
            "    Uninstalling tokenizers-0.21.4:\n",
            "      Successfully uninstalled tokenizers-0.21.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "============================================================\n",
            "IMPORTANT: Restart the kernel now before running the next cell!\n",
            "Kernel > Restart Kernel (or press 0,0 in command mode)\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\ammsh\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\~-kenizers\\\\tokenizers.pyd'\n",
            "Consider using the `--user` option or check the permissions.\n",
            "\n",
            "WARNING: You are using pip version 22.0.4; however, version 25.3 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "# Fix version compatibility - run this cell, then RESTART THE KERNEL before running the next cell\n",
        "# The kernel restart is required because old module versions are cached in memory\n",
        "\n",
        "# Downgrade NumPy to 1.x (TensorFlow was compiled against NumPy 1.x)\n",
        "%pip install \"numpy<2\"\n",
        "\n",
        "# Install compatible versions of sentence-transformers\n",
        "%pip install sentence-transformers==2.2.2 transformers==4.35.0\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"IMPORTANT: Restart the kernel now before running the next cell!\")\n",
        "print(\"Kernel > Restart Kernel (or press 0,0 in command mode)\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2302008c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
            "    self.io_loop.start()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
            "    self._run_once()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
            "    handle._run()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
            "    await result\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\ammsh\\AppData\\Local\\Temp\\ipykernel_42200\\98055812.py\", line 27, in <module>\n",
            "    from sentence_transformers import SentenceTransformer\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\__init__.py\", line 14, in <module>\n",
            "    from sentence_transformers.cross_encoder.CrossEncoder import CrossEncoder\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py\", line 3, in <module>\n",
            "    from .CrossEncoder import CrossEncoder\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py\", line 18, in <module>\n",
            "    from sentence_transformers.evaluation.SentenceEvaluator import SentenceEvaluator\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\evaluation\\__init__.py\", line 9, in <module>\n",
            "    from .NanoBEIREvaluator import NanoBEIREvaluator\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\evaluation\\NanoBEIREvaluator.py\", line 11, in <module>\n",
            "    from sentence_transformers import SentenceTransformer\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\", line 33, in <module>\n",
            "    from sentence_transformers.model_card import SentenceTransformerModelCardData, generate_model_card\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\model_card.py\", line 25, in <module>\n",
            "    from transformers.integrations import CodeCarbonCallback\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1781, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1793, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\integrations\\integration_utils.py\", line 36, in <module>\n",
            "    from .. import PreTrainedModel, TFPreTrainedModel\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1781, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1793, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py\", line 48, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\loss\\loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\loss\\loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\image_transforms.py\", line 50, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.eager import context\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 35, in <module>\n",
            "    from tensorflow.python.client import pywrap_tf_session\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\client\\pywrap_tf_session.py\", line 19, in <module>\n",
            "    from tensorflow.python.client._pywrap_tf_session import *\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
            "    self.io_loop.start()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
            "    self._run_once()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
            "    handle._run()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
            "    await result\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\ammsh\\AppData\\Local\\Temp\\ipykernel_42200\\98055812.py\", line 27, in <module>\n",
            "    from sentence_transformers import SentenceTransformer\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\__init__.py\", line 14, in <module>\n",
            "    from sentence_transformers.cross_encoder.CrossEncoder import CrossEncoder\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py\", line 3, in <module>\n",
            "    from .CrossEncoder import CrossEncoder\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py\", line 18, in <module>\n",
            "    from sentence_transformers.evaluation.SentenceEvaluator import SentenceEvaluator\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\evaluation\\__init__.py\", line 9, in <module>\n",
            "    from .NanoBEIREvaluator import NanoBEIREvaluator\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\evaluation\\NanoBEIREvaluator.py\", line 11, in <module>\n",
            "    from sentence_transformers import SentenceTransformer\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\", line 33, in <module>\n",
            "    from sentence_transformers.model_card import SentenceTransformerModelCardData, generate_model_card\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\model_card.py\", line 25, in <module>\n",
            "    from transformers.integrations import CodeCarbonCallback\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1781, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1793, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\integrations\\integration_utils.py\", line 36, in <module>\n",
            "    from .. import PreTrainedModel, TFPreTrainedModel\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1781, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1793, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py\", line 48, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\loss\\loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\loss\\loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\image_transforms.py\", line 50, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 42, in <module>\n",
            "    from tensorflow.python import data\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\", line 21, in <module>\n",
            "    from tensorflow.python.data import experimental\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\", line 95, in <module>\n",
            "    from tensorflow.python.data.experimental import service\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\", line 387, in <module>\n",
            "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\", line 22, in <module>\n",
            "    from tensorflow.python.data.experimental.ops import compression_ops\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py\", line 16, in <module>\n",
            "    from tensorflow.python.data.util import structure\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\", line 22, in <module>\n",
            "    from tensorflow.python.data.util import nest\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\", line 36, in <module>\n",
            "    from tensorflow.python.framework import sparse_tensor as _sparse_tensor\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\", line 24, in <module>\n",
            "    from tensorflow.python.framework import constant_op\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 25, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 23, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\", line 26, in <module>\n",
            "    from tensorflow.python.lib.core import _pywrap_bfloat16\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
            "    app.start()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
            "    self.io_loop.start()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
            "    self._run_once()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
            "    handle._run()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
            "    await result\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
            "    await super().execute_request(stream, ident, parent)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
            "    result = runner(coro)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
            "    if await self.run_code(code, result, async_=asy):\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"C:\\Users\\ammsh\\AppData\\Local\\Temp\\ipykernel_42200\\98055812.py\", line 27, in <module>\n",
            "    from sentence_transformers import SentenceTransformer\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\__init__.py\", line 14, in <module>\n",
            "    from sentence_transformers.cross_encoder.CrossEncoder import CrossEncoder\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py\", line 3, in <module>\n",
            "    from .CrossEncoder import CrossEncoder\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py\", line 18, in <module>\n",
            "    from sentence_transformers.evaluation.SentenceEvaluator import SentenceEvaluator\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\evaluation\\__init__.py\", line 9, in <module>\n",
            "    from .NanoBEIREvaluator import NanoBEIREvaluator\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\evaluation\\NanoBEIREvaluator.py\", line 11, in <module>\n",
            "    from sentence_transformers import SentenceTransformer\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\", line 33, in <module>\n",
            "    from sentence_transformers.model_card import SentenceTransformerModelCardData, generate_model_card\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sentence_transformers\\model_card.py\", line 25, in <module>\n",
            "    from transformers.integrations import CodeCarbonCallback\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1781, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1793, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\integrations\\integration_utils.py\", line 36, in <module>\n",
            "    from .. import PreTrainedModel, TFPreTrainedModel\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1781, in __getattr__\n",
            "    module = self._get_module(self._class_to_module[name])\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1793, in _get_module\n",
            "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py\", line 48, in <module>\n",
            "    from .loss.loss_utils import LOSS_MAPPING\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\loss\\loss_utils.py\", line 19, in <module>\n",
            "    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\loss\\loss_deformable_detr.py\", line 4, in <module>\n",
            "    from ..image_transforms import center_to_corners_format\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\image_transforms.py\", line 50, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py\", line 37, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 42, in <module>\n",
            "    from tensorflow.python import data\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py\", line 21, in <module>\n",
            "    from tensorflow.python.data import experimental\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\", line 95, in <module>\n",
            "    from tensorflow.python.data.experimental import service\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\", line 387, in <module>\n",
            "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\", line 22, in <module>\n",
            "    from tensorflow.python.data.experimental.ops import compression_ops\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py\", line 16, in <module>\n",
            "    from tensorflow.python.data.util import structure\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py\", line 22, in <module>\n",
            "    from tensorflow.python.data.util import nest\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\", line 36, in <module>\n",
            "    from tensorflow.python.framework import sparse_tensor as _sparse_tensor\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py\", line 24, in <module>\n",
            "    from tensorflow.python.framework import constant_op\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 25, in <module>\n",
            "    from tensorflow.python.eager import execute\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 23, in <module>\n",
            "    from tensorflow.python.framework import dtypes\n",
            "  File \"c:\\Users\\ammsh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py\", line 26, in <module>\n",
            "    from tensorflow.python.lib.core import _pywrap_bfloat16\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": []
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": []
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": []
        }
      ],
      "source": [
        "\"\"\"\n",
        "Compute SOC-level AI similarity from O*NET text using embeddings + cosine similarity.\n",
        "\n",
        "Inputs (download from O*NET Database, e.g., \"O*NET Database 29.x\"):\n",
        "  Place these files in a folder, e.g. ./onet_db/\n",
        "  Works best if you have at least ONE of:\n",
        "    - Task Statements.txt\n",
        "    - Skills.txt\n",
        "    - Technology Skills.txt\n",
        "    - Tools Used.txt\n",
        "    - Work Activities.txt\n",
        "    - Detailed Work Activities.txt\n",
        "    - Knowledge.txt\n",
        "    - Abilities.txt\n",
        "\n",
        "Output:\n",
        "  soc_ai_similarity.csv  (columns: onet_soc_code, soc_2018, ai_similarity, n_rows_used, text_len)\n",
        "\n",
        "Install:\n",
        "  pip install -U pandas numpy sentence-transformers scikit-learn\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "ONET_DIR = Path(\"onet_db\")  # folder containing O*NET .txt tables\n",
        "OUT_CSV = \"soc_ai_similarity.csv\"\n",
        "\n",
        "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "# AI anchor text: tune this (add your keywords/tools)\n",
        "AI_ANCHOR_TEXT = \"\"\"\n",
        "artificial intelligence AI machine learning ML deep learning neural networks\n",
        "large language models LLMs generative AI transformers embeddings prompt engineering\n",
        "natural language processing NLP computer vision CV speech recognition\n",
        "classification regression clustering forecasting anomaly detection recommendation systems\n",
        "automation decision support model deployment MLOps\n",
        "Python R SQL TensorFlow PyTorch scikit-learn XGBoost LightGBM\n",
        "vector databases retrieval augmented generation RAG\n",
        "\"\"\"\n",
        "\n",
        "# Optional: keep only SOC codes that look valid (O*NET-SOC style)\n",
        "SOC_PATTERN = re.compile(r\"^\\d{2}-\\d{4}\\.\\d{2}$|^\\d{2}-\\d{4}$\")\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def read_onet_table(path: Path) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    O*NET .txt tables are typically tab-delimited. We'll try tab first, then comma.\n",
        "    \"\"\"\n",
        "    for sep in [\"\\t\", \",\"]:\n",
        "        try:\n",
        "            df = pd.read_csv(path, sep=sep, dtype=str, engine=\"python\")\n",
        "            if df.shape[1] >= 2:\n",
        "                df.columns = [c.strip() for c in df.columns]\n",
        "                return df\n",
        "        except Exception:\n",
        "            pass\n",
        "    raise RuntimeError(f\"Could not parse {path.name} as tab or csv.\")\n",
        "\n",
        "def find_soc_col(df: pd.DataFrame) -> str | None:\n",
        "    \"\"\"\n",
        "    SOC code is usually in 'O*NET-SOC Code'. Sometimes 'ONET-SOC Code' or similar.\n",
        "    \"\"\"\n",
        "    candidates = [\n",
        "        \"O*NET-SOC Code\",\n",
        "        \"ONET-SOC Code\",\n",
        "        \"O_NET-SOC Code\",\n",
        "        \"onet_soc_code\",\n",
        "        \"SOC Code\",\n",
        "        \"SOC\",\n",
        "    ]\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    # fuzzy fallback\n",
        "    for c in df.columns:\n",
        "        if \"SOC\" in c.upper() and \"CODE\" in c.upper():\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def pick_text_cols(df: pd.DataFrame, table_name: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Choose columns that contain the actual descriptive text for each table.\n",
        "    \"\"\"\n",
        "    preferred = [\n",
        "        # Common text fields across O*NET tables\n",
        "        \"Task\",\n",
        "        \"Task Statement\",\n",
        "        \"Task Statement (Text)\",\n",
        "        \"Task Description\",\n",
        "        \"Description\",\n",
        "        \"Element Name\",\n",
        "        \"Work Activity\",\n",
        "        \"Detailed Work Activity\",\n",
        "        \"Technology Skill\",\n",
        "        \"Tool\",\n",
        "        \"Commodity Title\",\n",
        "        \"Title\",\n",
        "        \"Knowledge\",\n",
        "        \"Skill\",\n",
        "        \"Ability\",\n",
        "        \"Example\",\n",
        "        \"Sample of Reported Titles\",\n",
        "    ]\n",
        "    chosen = [c for c in preferred if c in df.columns]\n",
        "    if chosen:\n",
        "        return chosen\n",
        "\n",
        "    # fallback: pick object-like columns excluding obvious ids\n",
        "    drop_like = {\"scale id\", \"element id\", \"datavalue\", \"n\", \"standard error\", \"domain source\"}\n",
        "    cols = []\n",
        "    for c in df.columns:\n",
        "        cl = c.strip().lower()\n",
        "        if \"code\" in cl or \"id\" in cl:\n",
        "            continue\n",
        "        if any(k in cl for k in drop_like):\n",
        "            continue\n",
        "        cols.append(c)\n",
        "    # keep a reasonable number\n",
        "    return cols[:6]\n",
        "\n",
        "def normalize_soc_to_2018(onet_soc: str) -> str:\n",
        "    \"\"\"\n",
        "    Strip the .xx extension so '15-1252.00' -> '15-1252' (SOC 2018-like 6-digit occupation).\n",
        "    \"\"\"\n",
        "    if onet_soc is None:\n",
        "        return None\n",
        "    return str(onet_soc).split(\".\")[0].strip()\n",
        "\n",
        "def clean_text(s: str) -> str:\n",
        "    s = re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
        "    return s\n",
        "\n",
        "# -----------------------------\n",
        "# Load O*NET tables and build SOC text corpus\n",
        "# -----------------------------\n",
        "TABLE_FILES = [\n",
        "    \"Task Statements.txt\",\n",
        "    \"Skills.txt\",\n",
        "    \"Technology Skills.txt\",\n",
        "    \"Tools Used.txt\",\n",
        "    \"Work Activities.txt\",\n",
        "    \"Detailed Work Activities.txt\",\n",
        "    \"Knowledge.txt\",\n",
        "    \"Abilities.txt\",\n",
        "]\n",
        "\n",
        "rows = []\n",
        "\n",
        "for fname in TABLE_FILES:\n",
        "    fpath = ONET_DIR / fname\n",
        "    if not fpath.exists():\n",
        "        continue\n",
        "\n",
        "    df = read_onet_table(fpath)\n",
        "    soc_col = find_soc_col(df)\n",
        "    if soc_col is None:\n",
        "        continue\n",
        "\n",
        "    text_cols = pick_text_cols(df, fname)\n",
        "\n",
        "    # keep only needed cols\n",
        "    use = df[[soc_col] + text_cols].copy()\n",
        "    use = use.rename(columns={soc_col: \"onet_soc_code\"})\n",
        "\n",
        "    # concat text cols per row\n",
        "    use[\"row_text\"] = use[text_cols].astype(str).agg(\" | \".join, axis=1).map(clean_text)\n",
        "\n",
        "    # filter out empty row_text\n",
        "    use = use[use[\"row_text\"].str.len() > 0]\n",
        "\n",
        "    # optional SOC format filter\n",
        "    use[\"onet_soc_code\"] = use[\"onet_soc_code\"].astype(str).str.strip()\n",
        "    use = use[use[\"onet_soc_code\"].apply(lambda x: bool(SOC_PATTERN.match(x)) if isinstance(x, str) else False)]\n",
        "\n",
        "    use[\"source_table\"] = fname\n",
        "    rows.append(use[[\"onet_soc_code\", \"row_text\", \"source_table\"]])\n",
        "\n",
        "if not rows:\n",
        "    raise RuntimeError(\n",
        "        f\"No usable O*NET tables found in {ONET_DIR.resolve()}.\\n\"\n",
        "        f\"Put O*NET Database .txt files there (e.g., Task Statements.txt, Skills.txt, Technology Skills.txt).\"\n",
        "    )\n",
        "\n",
        "onet_long = pd.concat(rows, ignore_index=True)\n",
        "\n",
        "# aggregate all text per onet_soc_code\n",
        "soc_docs = (\n",
        "    onet_long.groupby(\"onet_soc_code\", as_index=False)[\"row_text\"]\n",
        "    .apply(lambda x: \"\\n\".join(x.tolist()))\n",
        "    .rename(columns={\"row_text\": \"doc\"})\n",
        ")\n",
        "\n",
        "soc_docs[\"soc_2018\"] = soc_docs[\"onet_soc_code\"].map(normalize_soc_to_2018)\n",
        "\n",
        "# Diagnostics\n",
        "soc_docs[\"text_len\"] = soc_docs[\"doc\"].str.len()\n",
        "\n",
        "# -----------------------------\n",
        "# Embed + cosine similarity\n",
        "# -----------------------------\n",
        "model = SentenceTransformer(MODEL_NAME)\n",
        "\n",
        "anchor_emb = model.encode([AI_ANCHOR_TEXT], normalize_embeddings=True)\n",
        "docs_emb = model.encode(soc_docs[\"doc\"].tolist(), normalize_embeddings=True, show_progress_bar=True)\n",
        "\n",
        "soc_docs[\"ai_similarity\"] = cosine_similarity(docs_emb, anchor_emb).ravel()\n",
        "\n",
        "# Optional: add how many underlying rows contributed (across all tables)\n",
        "counts = onet_long.groupby(\"onet_soc_code\").size().reset_index(name=\"n_rows_used\")\n",
        "soc_docs = soc_docs.merge(counts, on=\"onet_soc_code\", how=\"left\")\n",
        "\n",
        "# keep tidy output\n",
        "out = soc_docs[[\"onet_soc_code\", \"soc_2018\", \"ai_similarity\", \"n_rows_used\", \"text_len\"]].sort_values(\n",
        "    \"ai_similarity\", ascending=False\n",
        ")\n",
        "\n",
        "out.to_csv(OUT_CSV, index=False)\n",
        "print(f\"Wrote {OUT_CSV} with {len(out):,} SOC rows\")\n",
        "print(out.head(10))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
